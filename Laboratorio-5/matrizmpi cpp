#include <mpi.h>
#include <iostream>
#include <vector>

using namespace std;

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);

    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    const int N = 4; // Tamaño de la matriz y el vector
    vector<vector<int>> A(N, vector<int>(N, 1)); // Matriz NxN inicializada con 1
    vector<int> x(N, 1); // Vector inicializado con 1
    vector<int> y(N, 0); // Resultado

    int rows_per_process = N / size;

    // Buffer local para filas asignadas
    vector<vector<int>> local_A(rows_per_process, vector<int>(N));
    vector<int> local_y(rows_per_process, 0);

    // Distribuir las filas de A entre procesos
    MPI_Scatter(A.data(), rows_per_process * N, MPI_INT, 
                local_A.data(), rows_per_process * N, MPI_INT, 0, MPI_COMM_WORLD);

    // Transmitir el vector x a todos los procesos
    MPI_Bcast(x.data(), N, MPI_INT, 0, MPI_COMM_WORLD);

    // Multiplicación local
    for (int i = 0; i < rows_per_process; ++i) {
        for (int j = 0; j < N; ++j) {
            local_y[i] += local_A[i][j] * x[j];
        }
    }

    // Recolectar los resultados en el proceso raíz
    MPI_Gather(local_y.data(), rows_per_process, MPI_INT,
               y.data(), rows_per_process, MPI_INT, 0, MPI_COMM_WORLD);

    if (rank == 0) {
        cout << "Resultado y: ";
        for (int i = 0; i < N; ++i) {
            cout << y[i] << " ";
        }
        cout << endl;
    }

    MPI_Finalize();
    return 0;
}
